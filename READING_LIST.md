# Reading List

## On few-shot learning based on learning an initialization and fine-tuning procedure

* [Optimization as a model for few-shot learning](https://openreview.net/forum?id=rJY0-Kcll)
* [Model-agnostic meta-learning for fast adaptation of deep networks](https://arxiv.org/abs/1703.03400)
* [One-Shot Visual Imitation Learning via Meta-Learning](https://arxiv.org/abs/1709.04905)

## On few-shot learning based on a generic neural network architecture

* [One-Shot Learning with Memory-Augmented Neural Networks](https://arxiv.org/abs/1605.06065)
* [A Simple Neural Attentive Meta-Learner](https://openreview.net/forum?id=B1DmUzWAW)
* [One-Shot Imitation Learning](https://arxiv.org/abs/1703.07326)

## On adaptive language models

* [Improving neural language models with a continuous cache](https://arxiv.org/abs/1612.04426)
* [Dynamic evaluation of neural sequence models](https://arxiv.org/abs/1709.07432)

## On conditional language models using attention

* [Attention is all you need](https://arxiv.org/abs/1706.03762)

## On meta-learning for distribution learning:

* [One-Shot Generalization in Deep Generative Models](https://arxiv.org/abs/1603.05106)
* [Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions](https://arxiv.org/abs/1710.10304)

## On models for music generation  

* [Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription](http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf)
* [Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control](https://arxiv.org/abs/1611.02796)
* [Counterpoint by Convolution](https://openreview.net/forum?id=r1Usiwcex)
